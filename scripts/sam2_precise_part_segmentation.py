#!/usr/bin/env python3
"""
SAM2ç²¾å¯†ãƒ‘ãƒ¼ãƒ„ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³

å•é¡Œåˆ†æã¨æ ¹æœ¬çš„æ”¹å–„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼š
1. ã‚ˆã‚Šç²¾å¯†ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé…ç½®
2. è² ä¾‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å¼·åŒ–  
3. ãƒ‘ãƒ¼ãƒ„é–“ã®ç«¶åˆå›é¿
4. æ®µéšçš„ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
"""

import sys
import cv2
import numpy as np
import time
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
import json

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.core.utils import setup_logging, get_logger
from src.core.sam2.sam2_model import SAM2ModelManager
from src.core.sam2.prompt_handler import SAM2PromptHandler, PointPrompt

@dataclass
class SegmentationResult:
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµæœ"""
    part_name: str
    mask: np.ndarray
    score: float
    processing_time: float
    prompts_used: int
    strategy: str

class PrecisePartSegmenter:
    """ç²¾å¯†ãƒ‘ãƒ¼ãƒ„ã‚»ã‚°ãƒ¡ãƒ³ã‚¿ãƒ¼"""
    
    def __init__(self, sam2_manager: SAM2ModelManager):
        self.sam2_manager = sam2_manager
        self.logger = get_logger(__name__)
        
    def generate_precise_prompts(self, image_shape: Tuple[int, int], part_name: str) -> List[PointPrompt]:
        """ç²¾å¯†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        height, width = image_shape[:2]
        
        # ã‚ˆã‚Šç²¾å¯†ã§ä¿å®ˆçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé…ç½®
        precise_prompts = {
            "hair": [
                # é«ªã®ä¸­æ ¸éƒ¨åˆ†ã®ã¿ã«é›†ä¸­
                PointPrompt(width//2, height//8, 1, "é ­é ‚éƒ¨_é«ªã®æ¯›"),
                PointPrompt(width//3, height//5, 1, "å·¦é«ª_å†…å´"),
                PointPrompt(2*width//3, height//5, 1, "å³é«ª_å†…å´"),
                # å¼·åŠ›ãªé™¤å¤–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                PointPrompt(width//2, 2*height//5, 0, "é¡”_è‚Œ_é™¤å¤–"),
                PointPrompt(width//2, 3*height//5, 0, "é¦–_é™¤å¤–"),
                PointPrompt(width//2, 4*height//5, 0, "ä½“_é™¤å¤–"),
                PointPrompt(width//4, 2*height//5, 0, "å·¦é ¬_é™¤å¤–"),
                PointPrompt(3*width//4, 2*height//5, 0, "å³é ¬_é™¤å¤–"),
            ],
            "face": [
                # é¡”ã®ä¸­å¿ƒéƒ¨åˆ†ã«é›†ä¸­
                PointPrompt(width//2, 2*height//5, 1, "é¡”_ä¸­å¿ƒ"),
                PointPrompt(2*width//5, 2*height//5, 1, "å·¦é ¬_ä¸­å¤®"),
                PointPrompt(3*width//5, 2*height//5, 1, "å³é ¬_ä¸­å¤®"),
                PointPrompt(width//2, height//3, 1, "é¡_ä¸­å¤®"),
                # å¼·åŠ›ãªé™¤å¤–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                PointPrompt(width//2, height//6, 0, "é«ª_é™¤å¤–"),
                PointPrompt(width//2, 3*height//5, 0, "é¦–_é™¤å¤–"),
                PointPrompt(width//6, 2*height//5, 0, "å·¦èƒŒæ™¯_é™¤å¤–"),
                PointPrompt(5*width//6, 2*height//5, 0, "å³èƒŒæ™¯_é™¤å¤–"),
            ],
            "body": [
                # ä½“ã®ä¸­æ ¸éƒ¨åˆ†ã®ã¿
                PointPrompt(width//2, 3*height//5, 1, "èƒ´ä½“_ä¸­å¤®"),
                PointPrompt(2*width//5, 2*height//3, 1, "å·¦è‚©_å†…å´"),
                PointPrompt(3*width//5, 2*height//3, 1, "å³è‚©_å†…å´"),
                # å¼·åŠ›ãªé™¤å¤–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                PointPrompt(width//2, height//3, 0, "é¡”_é™¤å¤–"),
                PointPrompt(width//2, height//6, 0, "é«ª_é™¤å¤–"),
                PointPrompt(width//6, 3*height//5, 0, "å·¦èƒŒæ™¯_é™¤å¤–"),
                PointPrompt(5*width//6, 3*height//5, 0, "å³èƒŒæ™¯_é™¤å¤–"),
            ],
            "eyes": [
                # ç›®ã®éƒ¨åˆ†ã®ã¿ã«å³å¯†ã«é™å®š
                PointPrompt(2*width//5, 2*height//5, 1, "å·¦ç›®_ç³"),
                PointPrompt(3*width//5, 2*height//5, 1, "å³ç›®_ç³"),
                # å¼·åŠ›ãªé™¤å¤–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                PointPrompt(width//2, height//3, 0, "é¡_é™¤å¤–"),
                PointPrompt(width//2, height//2, 0, "é¼»_é™¤å¤–"),
                PointPrompt(width//2, 3*height//5, 0, "å£_é™¤å¤–"),
                PointPrompt(width//4, 2*height//5, 0, "å·¦é ¬_é™¤å¤–"),
                PointPrompt(3*width//4, 2*height//5, 0, "å³é ¬_é™¤å¤–"),
            ]
        }
        
        prompts = precise_prompts.get(part_name, precise_prompts["hair"])
        self.logger.info(f"  ğŸ¯ ç²¾å¯†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ: {len(prompts)}ç‚¹ ({part_name})")
        return prompts
    
    def segment_part_basic(self, image_rgb: np.ndarray, part_name: str) -> SegmentationResult:
        """åŸºæœ¬ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
        self.logger.info(f"ğŸ¯ {part_name.upper()}åŸºæœ¬ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")
        
        start_time = time.time()
        height, width = image_rgb.shape[:2]
        
        # ç²¾å¯†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        prompts = self.generate_precise_prompts((height, width), part_name)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåº§æ¨™ã¨ãƒ©ãƒ™ãƒ«ã‚’æº–å‚™
        point_coords = []
        point_labels = []
        
        for prompt in prompts:
            point_coords.append([prompt.x, prompt.y])
            point_labels.append(prompt.label)
        
        point_coords = np.array(point_coords) if point_coords else None
        point_labels = np.array(point_labels) if point_labels else None
        
        # SAM2ã§ç›´æ¥æ¨è«–å®Ÿè¡Œ
        masks, scores, logits = self.sam2_manager.predict(
            image=image_rgb,
            point_coords=point_coords,
            point_labels=point_labels,
            multimask_output=True
        )
        
        if len(masks) == 0:
            raise RuntimeError("ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµæœãªã—")
        
        # æœ€è‰¯ã®çµæœã‚’é¸æŠ
        best_idx = np.argmax(scores)
        best_mask = masks[best_idx]
        best_score = scores[best_idx]
        
        processing_time = time.time() - start_time
        
        result = SegmentationResult(
            part_name=part_name,
            mask=best_mask,
            score=best_score,
            processing_time=processing_time,
            prompts_used=len(prompts),
            strategy="precise_basic"
        )
        
        self.logger.info(f"  âœ… å®Œäº†: ã‚¹ã‚³ã‚¢ {best_score:.3f}, æ™‚é–“ {processing_time:.2f}s")
        return result
    
    def create_detailed_visualization(self, image_rgb: np.ndarray, result: SegmentationResult) -> np.ndarray:
        """è©³ç´°å¯è¦–åŒ–ï¼ˆãƒã‚¹ã‚¯å¢ƒç•Œã‚’æ˜ç¢ºã«è¡¨ç¤ºï¼‰"""
        vis_image = image_rgb.copy()
        
        # ãƒ‘ãƒ¼ãƒ„åˆ¥è‰²åˆ†ã‘
        colors = {
            "hair": [255, 100, 150],    # ãƒ”ãƒ³ã‚¯
            "face": [255, 200, 100],    # ã‚ªãƒ¬ãƒ³ã‚¸
            "body": [100, 200, 255],    # é’
            "eyes": [150, 255, 100],    # ç·‘
        }
        color = np.array(colors.get(result.part_name, [255, 255, 255]))
        
        # ãƒã‚¹ã‚¯é©ç”¨ï¼ˆã‚ˆã‚Šæ§ãˆã‚ã«ï¼‰
        mask_bool = result.mask.astype(bool)
        vis_image[mask_bool] = vis_image[mask_bool] * 0.7 + color * 0.3
        
        # ãƒã‚¹ã‚¯å¢ƒç•Œã‚’æç”»
        mask_uint8 = (result.mask * 255).astype(np.uint8)
        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(vis_image, contours, -1, color.tolist(), 2)
        
        # æƒ…å ±è¡¨ç¤º
        info_lines = [
            f"Part: {result.part_name.upper()}",
            f"Score: {result.score:.3f}",
            f"Strategy: {result.strategy}",
            f"Time: {result.processing_time:.2f}s",
            f"Prompts: {result.prompts_used}",
            f"Mask Area: {np.sum(result.mask):.0f} pixels",
            f"Coverage: {np.sum(result.mask) / result.mask.size * 100:.1f}%"
        ]
        
        for i, line in enumerate(info_lines):
            y_pos = 30 + i * 25
            text_size = cv2.getTextSize(line, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            cv2.rectangle(vis_image, (10, y_pos - 20), 
                         (text_size[0] + 20, y_pos + 5), (0, 0, 0), -1)
            cv2.putText(vis_image, line, (15, y_pos), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return vis_image
    
    def save_debug_results(self, image_rgb: np.ndarray, results: List[SegmentationResult], 
                          output_dir: Path, image_name: str) -> Dict[str, Any]:
        """ãƒ‡ãƒãƒƒã‚°çµæœä¿å­˜"""
        
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒä¿å­˜
        original_path = output_dir / f"original_{image_name}.png"
        original_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        cv2.imwrite(str(original_path), original_bgr)
        
        saved_files = {"original": str(original_path)}
        
        # ãƒ‘ãƒ¼ãƒ„åˆ¥çµæœä¿å­˜
        for result in results:
            part_name = result.part_name
            
            # ãƒã‚¹ã‚¯ç”»åƒä¿å­˜ï¼ˆãƒã‚¤ãƒŠãƒªï¼‰
            mask_path = output_dir / f"mask_{part_name}_{image_name}.png"
            cv2.imwrite(str(mask_path), (result.mask * 255).astype(np.uint8))
            saved_files[f"mask_{part_name}"] = str(mask_path)
            
            # ãƒã‚¹ã‚¯çµ±è¨ˆæƒ…å ±
            mask_stats = {
                "total_pixels": int(result.mask.size),
                "mask_pixels": int(np.sum(result.mask)),
                "coverage_percent": float(np.sum(result.mask) / result.mask.size * 100),
                "bounding_box": self.get_mask_bounding_box(result.mask)
            }
            
            # è©³ç´°å¯è¦–åŒ–ç”»åƒä¿å­˜
            vis_image = self.create_detailed_visualization(image_rgb, result)
            vis_path = output_dir / f"debug_visualization_{part_name}_{image_name}.png"
            vis_bgr = cv2.cvtColor(vis_image, cv2.COLOR_RGB2BGR)
            cv2.imwrite(str(vis_path), vis_bgr)
            saved_files[f"debug_vis_{part_name}"] = str(vis_path)
            
            # çµ±è¨ˆæƒ…å ±JSONä¿å­˜
            stats_path = output_dir / f"stats_{part_name}_{image_name}.json"
            with open(stats_path, 'w', encoding='utf-8') as f:
                json.dump(mask_stats, f, indent=2, ensure_ascii=False)
            saved_files[f"stats_{part_name}"] = str(stats_path)
        
        return saved_files
    
    def get_mask_bounding_box(self, mask: np.ndarray) -> Dict[str, int]:
        """ãƒã‚¹ã‚¯ã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹å–å¾—"""
        rows = np.any(mask, axis=1)
        cols = np.any(mask, axis=0)
        
        if not np.any(rows) or not np.any(cols):
            return {"x": 0, "y": 0, "width": 0, "height": 0}
        
        rmin, rmax = np.where(rows)[0][[0, -1]]
        cmin, cmax = np.where(cols)[0][[0, -1]]
        
        return {
            "x": int(cmin),
            "y": int(rmin), 
            "width": int(cmax - cmin + 1),
            "height": int(rmax - rmin + 1)
        }

def parse_args():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ"""
    parser = argparse.ArgumentParser(
        description="SAM2ç²¾å¯†ãƒ‘ãƒ¼ãƒ„ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½¿ç”¨
  python scripts/sam2_precise_part_segmentation.py
  
  # ç‰¹å®šãƒ•ã‚©ãƒ«ãƒ€ã‚’æŒ‡å®š
  python scripts/sam2_precise_part_segmentation.py --input data/samples/demo_images
  
  # anime_woman1ãƒ•ã‚©ãƒ«ãƒ€ã‚’æŒ‡å®š
  python scripts/sam2_precise_part_segmentation.py --input data/samples/anime_woman1
  
  # è¤‡æ•°ãƒ‘ãƒ¼ãƒ„ã‚’æŒ‡å®š
  python scripts/sam2_precise_part_segmentation.py --parts face hair body
  
  # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®š
  python scripts/sam2_precise_part_segmentation.py --output my_results
        """
    )
    
    parser.add_argument(
        "--input", "-i",
        type=str,
        default="data/samples/demo_images",
        help="å…¥åŠ›ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: data/samples/demo_imagesï¼‰"
    )
    
    parser.add_argument(
        "--output", "-o", 
        type=str,
        default="data/output/sam2_precise_segmentation",
        help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: data/output/sam2_precise_segmentationï¼‰"
    )
    
    parser.add_argument(
        "--parts", "-p",
        nargs="+",
        choices=["face", "hair", "body", "eyes"],
        default=["face", "hair", "body", "eyes"],
        help="ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å¯¾è±¡ãƒ‘ãƒ¼ãƒ„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: å…¨ãƒ‘ãƒ¼ãƒ„ï¼‰"
    )
    
    parser.add_argument(
        "--image-pattern", 
        type=str,
        default="*.png",
        help="ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: *.pngï¼‰"
    )
    
    parser.add_argument(
        "--max-images",
        type=int,
        default=None,
        help="å‡¦ç†ã™ã‚‹æœ€å¤§ç”»åƒæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: åˆ¶é™ãªã—ï¼‰"
    )
    
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="è©³ç´°ãƒ­ã‚°ã‚’è¡¨ç¤º"
    )
    
    return parser.parse_args()

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°è§£æ
    args = parse_args()
    
    # ãƒ­ã‚°è¨­å®š
    log_level = "DEBUG" if args.verbose else "INFO"
    setup_logging(level=log_level, console_output=True, structured=False)
    logger = get_logger(__name__)
    
    logger.info("=== SAM2ç²¾å¯†ãƒ‘ãƒ¼ãƒ„ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ ===")
    logger.info(f"ğŸ“ å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€: {args.input}")
    logger.info(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {args.output}")
    logger.info(f"ğŸ¯ å¯¾è±¡ãƒ‘ãƒ¼ãƒ„: {', '.join(args.parts)}")
    logger.info(f"ğŸ” ç”»åƒãƒ‘ã‚¿ãƒ¼ãƒ³: {args.image_pattern}")
    
    try:
        # å…¥åŠ›ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ç¢ºèª
        input_path = Path(args.input)
        if not input_path.is_absolute():
            input_path = project_root / input_path
            
        if not input_path.exists():
            logger.error(f"âŒ å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {input_path}")
            return
            
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
        image_files = list(input_path.glob(args.image_pattern))
        
        if not image_files:
            logger.error(f"âŒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            logger.error(f"   ãƒ•ã‚©ãƒ«ãƒ€: {input_path}")
            logger.error(f"   ãƒ‘ã‚¿ãƒ¼ãƒ³: {args.image_pattern}")
            
            # åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
            all_files = list(input_path.glob("*"))
            if all_files:
                logger.info("ğŸ“‚ ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«:")
                for file in all_files[:10]:  # æœ€åˆã®10ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
                    logger.info(f"   {file.name}")
                if len(all_files) > 10:
                    logger.info(f"   ... ä»– {len(all_files) - 10} ãƒ•ã‚¡ã‚¤ãƒ«")
            return
        
        # ç”»åƒæ•°åˆ¶é™
        if args.max_images and len(image_files) > args.max_images:
            logger.info(f"ğŸ“Š ç”»åƒæ•°ã‚’ {args.max_images} ã«åˆ¶é™")
            image_files = image_files[:args.max_images]
            
        logger.info(f"ğŸ“¸ å‡¦ç†å¯¾è±¡ç”»åƒæ•°: {len(image_files)}")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
        output_path = Path(args.output)
        if not output_path.is_absolute():
            output_path = project_root / output_path
        output_path.mkdir(parents=True, exist_ok=True)
        
        # SAM2ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        logger.info("ğŸ¤– SAM2ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–")
        sam2_manager = SAM2ModelManager(model_name="sam2_hiera_large.pt")
        if not sam2_manager.load_model():
            logger.error("âŒ SAM2ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—")
            return
        
        segmenter = PrecisePartSegmenter(sam2_manager)
        
        # å¯¾è±¡ãƒ‘ãƒ¼ãƒ„ï¼ˆã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰ï¼‰
        target_parts = args.parts
        
        # å…¨å‡¦ç†çµ±è¨ˆ
        total_images_processed = 0
        total_processing_time = 0
        all_results = []
        
        # å„ç”»åƒã§å‡¦ç†
        for image_idx, image_path in enumerate(image_files):
            logger.info(f"\nğŸ“¸ ç”»åƒå‡¦ç† ({image_idx + 1}/{len(image_files)}): {image_path.name}")
            
            try:
                # ç”»åƒèª­ã¿è¾¼ã¿
                image = cv2.imread(str(image_path))
                if image is None:
                    logger.warning(f"  âš ï¸ ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—: {image_path}")
                    continue
                    
                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                logger.info(f"  ğŸ“ ç”»åƒã‚µã‚¤ã‚º: {image_rgb.shape[1]}Ã—{image_rgb.shape[0]}")
                
                # å„ãƒ‘ãƒ¼ãƒ„ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
                image_results = []
                image_start_time = time.time()
                
                for part_name in target_parts:
                    logger.info(f"\n  ğŸ¯ {part_name.upper()}ãƒ‘ãƒ¼ãƒ„å‡¦ç†")
                    
                    try:
                        result = segmenter.segment_part_basic(image_rgb, part_name)
                        image_results.append(result)
                        
                        # å€‹åˆ¥çµæœãƒ­ã‚°
                        coverage = np.sum(result.mask) / result.mask.size * 100
                        logger.info(f"    ğŸ“Š ãƒã‚¹ã‚¯ã‚«ãƒãƒ¼ç‡: {coverage:.1f}%")
                        
                    except Exception as e:
                        logger.error(f"    âŒ {part_name}ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—: {e}")
                        continue
                
                image_processing_time = time.time() - image_start_time
                total_processing_time += image_processing_time
                
                if not image_results:
                    logger.warning(f"  âš ï¸ {image_path.name}ã®å‡¦ç†çµæœãŒã‚ã‚Šã¾ã›ã‚“")
                    continue
                
                # ãƒ‡ãƒãƒƒã‚°çµæœä¿å­˜
                logger.info(f"\n  ğŸ’¾ çµæœä¿å­˜ä¸­...")
                saved_files = segmenter.save_debug_results(image_rgb, image_results, output_path, image_path.stem)
                
                # ç”»åƒåˆ¥ã‚µãƒãƒªãƒ¼
                avg_score = np.mean([r.score for r in image_results])
                avg_coverage = np.mean([np.sum(r.mask) / r.mask.size * 100 for r in image_results])
                
                logger.info(f"  ğŸ“Š {image_path.name} å®Œäº†:")
                logger.info(f"    ğŸ¯ å‡¦ç†ãƒ‘ãƒ¼ãƒ„: {len(image_results)}")
                logger.info(f"    ğŸ“ˆ å¹³å‡ã‚¹ã‚³ã‚¢: {avg_score:.3f}")
                logger.info(f"    ğŸ“ å¹³å‡ã‚«ãƒãƒ¼ç‡: {avg_coverage:.1f}%")
                logger.info(f"    â±ï¸ å‡¦ç†æ™‚é–“: {image_processing_time:.2f}ç§’")
                
                all_results.extend(image_results)
                total_images_processed += 1
                
            except Exception as e:
                logger.error(f"  âŒ {image_path.name}å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        if not all_results:
            logger.warning("âš ï¸ å…¨ä½“ã®å‡¦ç†çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # å…¨ä½“çµ±è¨ˆåˆ†æ
        global_analysis = {
            "total_images_processed": total_images_processed,
            "total_processing_time": float(total_processing_time),
            "average_score": float(np.mean([r.score for r in all_results])),
            "average_coverage": float(np.mean([np.sum(r.mask) / r.mask.size * 100 for r in all_results])),
            "best_result": {
                "part": max(all_results, key=lambda r: r.score).part_name,
                "score": float(max(all_results, key=lambda r: r.score).score)
            },
            "worst_result": {
                "part": min(all_results, key=lambda r: r.score).part_name,
                "score": float(min(all_results, key=lambda r: r.score).score)
            }
        }
        
        # ãƒ‘ãƒ¼ãƒ„åˆ¥çµ±è¨ˆ
        parts_stats = {}
        for part in target_parts:
            part_results = [r for r in all_results if r.part_name == part]
            if part_results:
                parts_stats[part] = {
                    "count": len(part_results),
                    "average_score": float(np.mean([r.score for r in part_results])),
                    "average_coverage": float(np.mean([np.sum(r.mask) / r.mask.size * 100 for r in part_results])),
                    "best_score": float(max(part_results, key=lambda r: r.score).score),
                    "worst_score": float(min(part_results, key=lambda r: r.score).score)
                }
        
        global_analysis["parts_statistics"] = parts_stats
        
        # å…¨ä½“åˆ†æçµæœJSONä¿å­˜
        global_analysis_path = output_path / "global_analysis.json"
        with open(global_analysis_path, 'w', encoding='utf-8') as f:
            json.dump(global_analysis, f, indent=2, ensure_ascii=False)
        
        # æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼
        logger.info(f"\nğŸ‰ å…¨ä½“å‡¦ç†å®Œäº†!")
        logger.info(f"ğŸ“Š å‡¦ç†çµ±è¨ˆ:")
        logger.info(f"  ğŸ“¸ å‡¦ç†ç”»åƒæ•°: {total_images_processed}/{len(image_files)}")
        logger.info(f"  ğŸ¯ ç·ãƒ‘ãƒ¼ãƒ„æ•°: {len(all_results)}")
        logger.info(f"  ğŸ“ˆ å…¨ä½“å¹³å‡ã‚¹ã‚³ã‚¢: {global_analysis['average_score']:.3f}")
        logger.info(f"  ğŸ“ å…¨ä½“å¹³å‡ã‚«ãƒãƒ¼ç‡: {global_analysis['average_coverage']:.1f}%")
        logger.info(f"  â±ï¸ ç·å‡¦ç†æ™‚é–“: {total_processing_time:.2f}ç§’")
        logger.info(f"  ğŸ† æœ€é«˜æ€§èƒ½: {global_analysis['best_result']['part']} ({global_analysis['best_result']['score']:.3f})")
        
        # ãƒ‘ãƒ¼ãƒ„åˆ¥çµ±è¨ˆè¡¨ç¤º
        logger.info(f"\nğŸ“ ãƒ‘ãƒ¼ãƒ„åˆ¥çµ±è¨ˆ:")
        for part, stats in parts_stats.items():
            logger.info(f"  {part:6}: {stats['count']:2}ä»¶, "
                       f"å¹³å‡ã‚¹ã‚³ã‚¢ {stats['average_score']:.3f}, "
                       f"å¹³å‡ã‚«ãƒãƒ¼ç‡ {stats['average_coverage']:4.1f}%")
        
        logger.info(f"\nğŸ“ çµæœä¿å­˜å…ˆ: {output_path}")
        logger.info(f"ğŸ“‹ å…¨ä½“åˆ†æ: {global_analysis_path}")
        logger.info("âœ¨ ç²¾å¯†ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è§£æå®Œäº†!")
        
    except Exception as e:
        logger.error(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
        if 'sam2_manager' in locals():
            sam2_manager.unload_model()

if __name__ == "__main__":
    main()