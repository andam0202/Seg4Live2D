#!/usr/bin/env python3
"""
SAM2è©³ç´°ãƒ‘ãƒ¼ãƒ„ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ

Live2Dç”¨ã®ç´°ã‹ã„ãƒ‘ãƒ¼ãƒ„ï¼ˆè§’ãƒ»é–ãƒ»é¦–è¼ªãƒ»ç›®ãƒ»çœ‰ãƒ»å£ãªã©ï¼‰ã‚’å€‹åˆ¥ã«ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
"""

import sys
import cv2
import numpy as np
import time
from pathlib import Path
from typing import Dict, List, Tuple, Any
from dataclasses import dataclass

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.core.utils import setup_logging, get_logger
from src.core.sam2.sam2_model import SAM2ModelManager
from src.core.sam2.prompt_handler import SAM2PromptHandler, PointPrompt

@dataclass
class MainPartPrompts:
    """ä¸»è¦ãƒ‘ãƒ¼ãƒ„ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚»ãƒƒãƒˆ"""
    
    @staticmethod
    def hair(image_shape: Tuple[int, int]) -> List[PointPrompt]:
        """é«ªã®æ¯›ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        height, width = image_shape[:2]
        
        return [
            PointPrompt(width//2, height//4, 1, description="é«ª_ä¸­å¤®"),
            PointPrompt(width//4, height//3, 1, description="é«ª_å·¦"),
            PointPrompt(width*3//4, height//3, 1, description="é«ª_å³"),
            PointPrompt(width//2, height//6, 1, description="é«ª_ä¸Šéƒ¨"),
            PointPrompt(width//6, height//2, 1, description="é«ª_å·¦ã‚µã‚¤ãƒ‰"),
            PointPrompt(width*5//6, height//2, 1, description="é«ª_å³ã‚µã‚¤ãƒ‰"),
            # èƒŒæ™¯é™¤å¤–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            PointPrompt(width//2, height//2, 0, description="é¡”_èƒŒæ™¯"),
            PointPrompt(width//2, height*2//3, 0, description="ä½“_èƒŒæ™¯"),
        ]
    
    @staticmethod
    def horns(image_shape: Tuple[int, int]) -> List[PointPrompt]:
        """è§’ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        height, width = image_shape[:2]
        
        return [
            PointPrompt(width//2 - 60, height//8, 1, description="å·¦è§’"),
            PointPrompt(width//2 + 60, height//8, 1, description="å³è§’"),
            PointPrompt(width//2, height//10, 1, description="è§’_ä¸­å¤®"),
            PointPrompt(width//2 - 80, height//6, 1, description="å·¦è§’_å…ˆç«¯"),
            PointPrompt(width//2 + 80, height//6, 1, description="å³è§’_å…ˆç«¯"),
            # èƒŒæ™¯é™¤å¤–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            PointPrompt(width//2, height//4, 0, description="é«ª_èƒŒæ™¯"),
            PointPrompt(width//4, height//5, 0, description="å·¦å´_èƒŒæ™¯"),
            PointPrompt(width*3//4, height//5, 0, description="å³å´_èƒŒæ™¯"),
        ]
    
    @staticmethod
    def face(image_shape: Tuple[int, int]) -> List[PointPrompt]:
        """é¡”ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        height, width = image_shape[:2]
        
        return [
            PointPrompt(width//2, height//2, 1, description="é¡”_ä¸­å¤®"),
            PointPrompt(width*2//5, height*2//5, 1, description="å·¦ç›®"),
            PointPrompt(width*3//5, height*2//5, 1, description="å³ç›®"),
            PointPrompt(width//2, height//2 + 40, 1, description="å£"),
            PointPrompt(width//2, height//2 + 10, 1, description="é¼»"),
            PointPrompt(width//3, height//2, 1, description="å·¦é ¬"),
            PointPrompt(width*2//3, height//2, 1, description="å³é ¬"),
            # èƒŒæ™¯é™¤å¤–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            PointPrompt(width//2, height//3, 0, description="é«ª_èƒŒæ™¯"),
            PointPrompt(width//2, height*3//5, 0, description="é¦–è¼ª_èƒŒæ™¯"),
        ]
    
    @staticmethod
    def body(image_shape: Tuple[int, int]) -> List[PointPrompt]:
        """èº«ä½“ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        height, width = image_shape[:2]
        
        return [
            PointPrompt(width//2, height*2//3, 1, description="ä½“_ä¸­å¤®"),
            PointPrompt(width//3, height*3//4, 1, description="ä½“_å·¦"),
            PointPrompt(width*2//3, height*3//4, 1, description="ä½“_å³"),
            PointPrompt(width//2, height*3//4, 1, description="èƒ¸éƒ¨"),
            PointPrompt(width//2, height*5//6, 1, description="ä¸‹åŠèº«"),
            # èƒŒæ™¯é™¤å¤–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            PointPrompt(width//2, height//2, 0, description="é¡”_èƒŒæ™¯"),
            PointPrompt(width//4, height*2//3, 0, description="å·¦è…•_èƒŒæ™¯"),
            PointPrompt(width*3//4, height*2//3, 0, description="å³è…•_èƒŒæ™¯"),
        ]
    
    @staticmethod
    def collar(image_shape: Tuple[int, int]) -> List[PointPrompt]:
        """é¦–è¼ªã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        height, width = image_shape[:2]
        
        return [
            PointPrompt(width//2, height*11//24, 1, description="é¦–è¼ª_ä¸­å¤®"),
            PointPrompt(width//2 - 50, height*11//24, 1, description="é¦–è¼ª_å·¦"),
            PointPrompt(width//2 + 50, height*11//24, 1, description="é¦–è¼ª_å³"),
            PointPrompt(width//2, height*11//24 - 8, 1, description="é¦–è¼ª_ä¸Š"),
            PointPrompt(width//2, height*11//24 + 8, 1, description="é¦–è¼ª_ä¸‹"),
            PointPrompt(width//2, height*2//5, 1, description="é–"),
            # èƒŒæ™¯é™¤å¤–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            PointPrompt(width//2, height*2//5 - 20, 0, description="é¡”_èƒŒæ™¯"),
            PointPrompt(width//2, height//2, 0, description="ä½“_èƒŒæ™¯"),
        ]

def add_text_with_background(
    image: np.ndarray, 
    text: str, 
    position: Tuple[int, int], 
    font_scale: float = 0.7,
    thickness: int = 2,
    text_color: Tuple[int, int, int] = (255, 255, 255),
    bg_color: Tuple[int, int, int] = (0, 0, 0),
    padding: int = 5
) -> None:
    """èƒŒæ™¯ä»˜ããƒ†ã‚­ã‚¹ãƒˆã‚’ç”»åƒã«è¿½åŠ """
    
    font = cv2.FONT_HERSHEY_SIMPLEX
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºã‚’è¨ˆç®—
    (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)
    
    x, y = position
    
    # èƒŒæ™¯çŸ©å½¢ã‚’æç”»
    bg_x1 = x - padding
    bg_y1 = y - text_height - padding
    bg_x2 = x + text_width + padding
    bg_y2 = y + baseline + padding
    
    cv2.rectangle(image, (bg_x1, bg_y1), (bg_x2, bg_y2), bg_color, -1)
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚’æç”»
    cv2.putText(image, text, (x, y), font, font_scale, text_color, thickness)

def test_detailed_part_segmentation(
    image_rgb: np.ndarray,
    part_name: str,
    prompts: List[PointPrompt],
    sam2_manager: SAM2ModelManager,
    output_dir: Path,
    image_name: str
) -> Dict[str, Any]:
    """è©³ç´°ãƒ‘ãƒ¼ãƒ„ã®å€‹åˆ¥ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""
    logger = get_logger(__name__)
    
    try:
        logger.info(f"  ğŸ¯ {part_name} ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®š
        handler = SAM2PromptHandler()
        handler.start_new_session()
        
        for prompt in prompts:
            handler.add_point_prompt(
                prompt.x, prompt.y, prompt.label,
                description=prompt.description
            )
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        start_time = time.time()
        sam2_prompts = handler.get_sam2_prompts()
        masks, scores, logits = sam2_manager.predict(
            image=image_rgb,
            **sam2_prompts,
            multimask_output=True
        )
        inference_time = time.time() - start_time
        
        # çµæœåˆ†æ
        best_mask_idx = np.argmax(scores)
        best_score = float(scores[best_mask_idx])
        best_mask = masks[best_mask_idx].astype(bool)
        mask_coverage = float(np.sum(best_mask) / best_mask.size)
        
        # å¯è¦–åŒ–ç”»åƒä½œæˆ
        overlay = image_rgb.copy().astype(np.float32)
        
        # ãƒ‘ãƒ¼ãƒ„åˆ¥è‰²åˆ†ã‘
        part_colors = {
            "hair": [255, 150, 0],       # ã‚ªãƒ¬ãƒ³ã‚¸
            "horns": [255, 200, 0],      # é‡‘è‰²
            "face": [255, 200, 150],     # è‚Œè‰²
            "body": [100, 150, 255],     # é’ç³»
            "collar": [150, 150, 150],   # ã‚·ãƒ«ãƒãƒ¼
        }
        
        color = np.array(part_colors.get(part_name, [255, 255, 100]))
        
        # ãƒã‚¹ã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
        overlay[best_mask] = overlay[best_mask] * 0.5 + color * 0.5
        overlay_image = overlay.astype(np.uint8)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç‚¹ã‚’æç”»
        prompt_coords = sam2_prompts["point_coords"]
        prompt_labels = sam2_prompts["point_labels"]
        
        if prompt_coords is not None:
            for i, ((x, y), label) in enumerate(zip(prompt_coords, prompt_labels)):
                # å‰æ™¯ç‚¹ã¯ç·‘ã€èƒŒæ™¯ç‚¹ã¯èµ¤
                point_color = (0, 255, 0) if label == 1 else (255, 0, 0)
                cv2.circle(overlay_image, (int(x), int(y)), 6, point_color, -1)
                cv2.circle(overlay_image, (int(x), int(y)), 8, (255, 255, 255), 2)
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç•ªå·
                add_text_with_background(
                    overlay_image, str(i+1),
                    (int(x)+12, int(y)),
                    font_scale=0.5,
                    text_color=(255, 255, 255),
                    bg_color=(0, 0, 0)
                )
        
        # çµæœæƒ…å ±ã‚’ç”»åƒã«è¡¨ç¤º
        info_lines = [
            f"Part: {part_name}",
            f"Score: {best_score:.3f}",
            f"Time: {inference_time:.2f}s",
            f"Coverage: {mask_coverage*100:.1f}%",
            f"Prompts: {len(prompts)}"
        ]
        
        for i, line in enumerate(info_lines):
            add_text_with_background(
                overlay_image, line,
                (10, 25 + i * 25),
                font_scale=0.6,
                text_color=(255, 255, 255),
                bg_color=(0, 0, 0)
            )
        
        # ç”»åƒä¿å­˜
        output_path = output_dir / f"{part_name}_{image_name}.png"
        overlay_bgr = cv2.cvtColor(overlay_image, cv2.COLOR_RGB2BGR)
        cv2.imwrite(str(output_path), overlay_bgr)
        
        logger.info(f"    ã‚¹ã‚³ã‚¢: {best_score:.3f}, ã‚«ãƒãƒ¬ãƒƒã‚¸: {mask_coverage*100:.1f}%, æ™‚é–“: {inference_time:.2f}s")
        
        return {
            "part_name": part_name,
            "score": best_score,
            "inference_time": inference_time,
            "mask_coverage": mask_coverage,
            "num_prompts": len(prompts),
            "output_path": str(output_path)
        }
        
    except Exception as e:
        logger.error(f"ãƒ‘ãƒ¼ãƒ„ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•— {part_name}: {e}")
        return {"error": str(e)}

def create_summary_grid(
    image_rgb: np.ndarray,
    all_results: List[Dict[str, Any]],
    output_path: Path
) -> None:
    """å…¨ãƒ‘ãƒ¼ãƒ„ã®çµæœã‚µãƒãƒªãƒ¼ã‚°ãƒªãƒƒãƒ‰ã‚’ä½œæˆ"""
    logger = get_logger(__name__)
    
    try:
        height, width = image_rgb.shape[:2]
        
        # 2x3ã‚°ãƒªãƒƒãƒ‰ï¼ˆ5ãƒ‘ãƒ¼ãƒ„ + 1å…ƒç”»åƒï¼‰
        grid_rows, grid_cols = 2, 3
        grid_image = np.zeros((height * grid_rows, width * grid_cols, 3), dtype=np.uint8)
        
        # å…ƒç”»åƒã‚’å·¦ä¸Šã«é…ç½®
        grid_image[0:height, 0:width] = image_rgb
        
        # å…ƒç”»åƒã«ã‚¿ã‚¤ãƒˆãƒ«è¿½åŠ 
        title_image = image_rgb.copy()
        add_text_with_background(
            title_image, "Original Image",
            (10, 30),
            font_scale=1.0,
            text_color=(255, 255, 255),
            bg_color=(0, 0, 0)
        )
        grid_image[0:height, 0:width] = title_image
        
        # å„ãƒ‘ãƒ¼ãƒ„çµæœã‚’é…ç½®
        positions = []
        for row in range(grid_rows):
            for col in range(grid_cols):
                if row == 0 and col == 0:  # å…ƒç”»åƒã‚¹ã‚­ãƒƒãƒ—
                    continue
                positions.append((row, col))
        
        for idx, result in enumerate(all_results[:5]):  # æœ€å¤§5ãƒ‘ãƒ¼ãƒ„
            if "error" in result:
                continue
                
            row, col = positions[idx]
            y_start, y_end = row * height, (row + 1) * height
            x_start, x_end = col * width, (col + 1) * width
            
            # ãƒ‘ãƒ¼ãƒ„ç”»åƒèª­ã¿è¾¼ã¿
            if "output_path" in result:
                part_image_path = Path(result["output_path"])
                if part_image_path.exists():
                    part_image = cv2.imread(str(part_image_path))
                    part_image_rgb = cv2.cvtColor(part_image, cv2.COLOR_BGR2RGB)
                    
                    # ã‚°ãƒªãƒƒãƒ‰ã«é…ç½®
                    grid_image[y_start:y_end, x_start:x_end] = part_image_rgb
        
        # ä¿å­˜
        grid_bgr = cv2.cvtColor(grid_image, cv2.COLOR_RGB2BGR)
        cv2.imwrite(str(output_path), grid_bgr)
        logger.info(f"ã‚µãƒãƒªãƒ¼ã‚°ãƒªãƒƒãƒ‰ä¿å­˜: {output_path}")
        
    except Exception as e:
        logger.error(f"ã‚µãƒãƒªãƒ¼ã‚°ãƒªãƒƒãƒ‰ä½œæˆå¤±æ•—: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    
    # ãƒ­ã‚°è¨­å®š
    setup_logging(level="INFO", console_output=True, structured=False)
    logger = get_logger(__name__)
    
    logger.info("=== SAM2è©³ç´°ãƒ‘ãƒ¼ãƒ„ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ ===")
    
    try:
        # ãƒ†ã‚¹ãƒˆç”»åƒå–å¾—
        sample_images_path = project_root / "data" / "samples" / "demo_images"
        image_files = list(sample_images_path.glob("*.png"))
        
        if not image_files:
            logger.error("âŒ ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
        output_dir = project_root / "data" / "output" / "sam2_detailed_parts"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # SAM2ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆæœ€é«˜ç²¾åº¦ã®largeãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
        sam2_manager = SAM2ModelManager(model_name="sam2_hiera_large.pt")
        if not sam2_manager.load_model():
            logger.error("âŒ SAM2ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—")
            return
        
        all_images_results = []
        
        # å…¨ã¦ã®ç”»åƒã§ãƒ†ã‚¹ãƒˆ
        for img_idx, image_path in enumerate(image_files):
            logger.info(f"\\nğŸ“¸ ç”»åƒ {img_idx + 1}/{len(image_files)}: {image_path.name}")
            
            # ç”»åƒèª­ã¿è¾¼ã¿
            image = cv2.imread(str(image_path))
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            height, width = image_rgb.shape[:2]
            
            logger.info(f"   ç”»åƒã‚µã‚¤ã‚º: {width}x{height}")
            
            # ä¸»è¦ãƒ‘ãƒ¼ãƒ„å®šç¾©ï¼ˆ5ãƒ‘ãƒ¼ãƒ„ï¼‰
            main_parts = {
                "hair": MainPartPrompts.hair((height, width)),
                "horns": MainPartPrompts.horns((height, width)),
                "face": MainPartPrompts.face((height, width)),
                "body": MainPartPrompts.body((height, width)),
                "collar": MainPartPrompts.collar((height, width)),
            }
            
            image_results = []
            
            # å„ãƒ‘ãƒ¼ãƒ„ã‚’ãƒ†ã‚¹ãƒˆ
            for part_name, prompts in main_parts.items():
                result = test_detailed_part_segmentation(
                    image_rgb, part_name, prompts, sam2_manager, 
                    output_dir, image_path.stem
                )
                
                if "error" not in result:
                    result["image_name"] = image_path.stem
                    image_results.append(result)
            
            all_images_results.extend(image_results)
            
            # ç”»åƒåˆ¥ã‚µãƒãƒªãƒ¼ã‚°ãƒªãƒƒãƒ‰ä½œæˆ
            summary_path = output_dir / f"detailed_parts_summary_{image_path.stem}.png"
            create_summary_grid(image_rgb, image_results, summary_path)
        
        # å…¨ä½“çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º
        logger.info(f"\\nğŸ“Š å…¨ç”»åƒã§ã®è©³ç´°ãƒ‘ãƒ¼ãƒ„ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµæœ:")
        
        # ãƒ‘ãƒ¼ãƒ„åˆ¥å¹³å‡ã‚¹ã‚³ã‚¢è¨ˆç®—
        part_stats = {}
        for result in all_images_results:
            part_name = result["part_name"]
            if part_name not in part_stats:
                part_stats[part_name] = {"scores": [], "times": [], "coverages": []}
            
            part_stats[part_name]["scores"].append(result["score"])
            part_stats[part_name]["times"].append(result["inference_time"])
            part_stats[part_name]["coverages"].append(result["mask_coverage"])
        
        # ãƒ‘ãƒ¼ãƒ„åˆ¥çµ±è¨ˆè¡¨ç¤º
        logger.info(f"\\nğŸ“ˆ ãƒ‘ãƒ¼ãƒ„åˆ¥çµ±è¨ˆï¼ˆ{len(image_files)}ç”»åƒå¹³å‡ï¼‰:")
        sorted_parts = sorted(part_stats.items(), 
                            key=lambda x: np.mean(x[1]["scores"]), reverse=True)
        
        for part_name, stats in sorted_parts:
            avg_score = np.mean(stats["scores"])
            std_score = np.std(stats["scores"])
            avg_time = np.mean(stats["times"])
            avg_coverage = np.mean(stats["coverages"]) * 100
            
            logger.info(f"  {part_name:15} - ã‚¹ã‚³ã‚¢: {avg_score:.3f}(Â±{std_score:.3f}), "
                      f"ã‚«ãƒãƒ¬ãƒƒã‚¸: {avg_coverage:4.1f}%, æ™‚é–“: {avg_time:.2f}s")
        
        # å…¨ä½“çµ±è¨ˆæƒ…å ±
        all_scores = [r["score"] for r in all_images_results]
        all_times = [r["inference_time"] for r in all_images_results]
        
        logger.info(f"\\nğŸ“Š å…¨ä½“çµ±è¨ˆæƒ…å ±:")
        logger.info(f"  ç·ãƒ†ã‚¹ãƒˆæ•°: {len(all_images_results)} ({len(image_files)}ç”»åƒ x 5ãƒ‘ãƒ¼ãƒ„)")
        logger.info(f"  å¹³å‡ã‚¹ã‚³ã‚¢: {np.mean(all_scores):.3f} (Â±{np.std(all_scores):.3f})")
        logger.info(f"  æœ€é«˜ã‚¹ã‚³ã‚¢: {np.max(all_scores):.3f}")
        logger.info(f"  æœ€ä½ã‚¹ã‚³ã‚¢: {np.min(all_scores):.3f}")
        logger.info(f"  å¹³å‡å‡¦ç†æ™‚é–“: {np.mean(all_times):.2f}s")
        logger.info(f"  ç·å‡¦ç†æ™‚é–“: {np.sum(all_times):.1f}s")
        
        # é«˜æ€§èƒ½ãƒ‘ãƒ¼ãƒ„ç‰¹å®š
        high_score_parts = [part for part, stats in part_stats.items() 
                           if np.mean(stats["scores"]) >= 0.9]
        
        if high_score_parts:
            logger.info(f"\\nğŸ† é«˜ç²¾åº¦ãƒ‘ãƒ¼ãƒ„ (ã‚¹ã‚³ã‚¢â‰¥0.9): {', '.join(high_score_parts)}")
        
        logger.info(f"\\nğŸ‰ å…¨ç”»åƒã§ã®ä¸»è¦ãƒ‘ãƒ¼ãƒ„ãƒ†ã‚¹ãƒˆå®Œäº†!")
        logger.info(f"çµæœ: {output_dir}")
        logger.info(f"  - å€‹åˆ¥ãƒ‘ãƒ¼ãƒ„: [part_name]_[image_name].png")
        logger.info(f"  - ç”»åƒåˆ¥ã‚µãƒãƒªãƒ¼: detailed_parts_summary_[image_name].png")
        logger.info(f"  - ãƒ†ã‚¹ãƒˆå¯¾è±¡: é«ªã®æ¯›ã€è§’ã€é¡”ã€èº«ä½“ã€é¦–è¼ª")
        
    except Exception as e:
        logger.error(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
        if 'sam2_manager' in locals():
            sam2_manager.unload_model()

if __name__ == "__main__":
    main()